{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome! # Hey there! This website serves as documentation for my k8s homelab. Here, you'll find guides , useful links and solutions to any issues I might have faced. If you have any questions or just want to chat, feel free to hit me up on any of my socials located in the footer!","title":"Introduction"},{"location":"#welcome","text":"Hey there! This website serves as documentation for my k8s homelab. Here, you'll find guides , useful links and solutions to any issues I might have faced. If you have any questions or just want to chat, feel free to hit me up on any of my socials located in the footer!","title":"Welcome!"},{"location":"apps/oauth2-proxy/","text":"OAuth2 Proxy slows down k8s cluster # The Problem # When ingress-nginx and oauth2-proxy are used together in a k8s cluster, as described in this tutorial , the cluster immediately starts slowing down when accessing any application using HTTP / HTTPS that go through the ingress. The issue is described further in this stackoverflow post The Cause # Setting the following in an application's annotation causes this issue annotations : nginx.ingress.kubernetes.io/auth-url : \"http://auth.domain.com/oauth2/auth\" nginx.ingress.kubernetes.io/auth-signin : \"https://auth.domain.com/oauth2/sign_in\" Why does adding these annotations cause the issue? # When auth-url is set to auth.domain.com , this means that the request goes outside the cluster (so-called hairpin mode), and goes back via External IP of Ingress that routes to internal ClusterIP Service (which adds extra network hops), instead going directly with ClusterIP/Service DNS name (you stay within Kubernetes cluster) 1 If a request is made to auth.domain.com from inside the internal network, the internal DNS resolves this to an internal IP. If a request is made to auth.domain.com from outside the network, the external DNS (cloudflare, google, etc...) resolves this to the external IP set in the DNS records. Note This doesn't happen with other repos (the ones at awesome-home-kubernetes ) because they use a split-horizon DNS , meaning they have a DNS internal to their network that resolves queries to internal IPs and another one externaly that resolves queries to external IPs. The Solution # Set the auth-url to the internal oauth2 service so that the application doesn't resolve the auth-url to an external IP. annotations : nginx.ingress.kubernetes.io/auth-url : \"http://oauth2-proxy.networking.svc.cluster.local/oauth2/auth\" nginx.ingress.kubernetes.io/auth-signin : \"https://auth.domain.com/oauth2/sign_in\" https://stackoverflow.com/a/60280114 \u21a9","title":"Apps"},{"location":"apps/oauth2-proxy/#oauth2-proxy-slows-down-k8s-cluster","text":"","title":"OAuth2 Proxy slows down k8s cluster"},{"location":"apps/oauth2-proxy/#the-problem","text":"When ingress-nginx and oauth2-proxy are used together in a k8s cluster, as described in this tutorial , the cluster immediately starts slowing down when accessing any application using HTTP / HTTPS that go through the ingress. The issue is described further in this stackoverflow post","title":"The Problem"},{"location":"apps/oauth2-proxy/#the-cause","text":"Setting the following in an application's annotation causes this issue annotations : nginx.ingress.kubernetes.io/auth-url : \"http://auth.domain.com/oauth2/auth\" nginx.ingress.kubernetes.io/auth-signin : \"https://auth.domain.com/oauth2/sign_in\"","title":"The Cause"},{"location":"apps/oauth2-proxy/#why-does-adding-these-annotations-cause-the-issue","text":"When auth-url is set to auth.domain.com , this means that the request goes outside the cluster (so-called hairpin mode), and goes back via External IP of Ingress that routes to internal ClusterIP Service (which adds extra network hops), instead going directly with ClusterIP/Service DNS name (you stay within Kubernetes cluster) 1 If a request is made to auth.domain.com from inside the internal network, the internal DNS resolves this to an internal IP. If a request is made to auth.domain.com from outside the network, the external DNS (cloudflare, google, etc...) resolves this to the external IP set in the DNS records. Note This doesn't happen with other repos (the ones at awesome-home-kubernetes ) because they use a split-horizon DNS , meaning they have a DNS internal to their network that resolves queries to internal IPs and another one externaly that resolves queries to external IPs.","title":"Why does adding these annotations cause the issue?"},{"location":"apps/oauth2-proxy/#the-solution","text":"Set the auth-url to the internal oauth2 service so that the application doesn't resolve the auth-url to an external IP. annotations : nginx.ingress.kubernetes.io/auth-url : \"http://oauth2-proxy.networking.svc.cluster.local/oauth2/auth\" nginx.ingress.kubernetes.io/auth-signin : \"https://auth.domain.com/oauth2/sign_in\" https://stackoverflow.com/a/60280114 \u21a9","title":"The Solution"},{"location":"cluster_setup/adding_sops_support_to_flux/","text":"","title":"Adding sops support to flux"},{"location":"cluster_setup/installing_k3s/","text":"Installing k3s # k3s is a lightweight version of Kubernetes, meant to be used on edge devices, in CI, ARM boards and so on. It's basically a single binary that contains everything to get kubernetes up and running. To help us with installing k3s , we're going to be using a utility package called k3sup Creating your cluster # Getting your cluster up and running is as simple as running this command from your local machine k3sup install --ip <master_ip> --user master --local-path ~/.kube/config --merge --context homelab --ssh-key <ssh_key> --k3s-channel latest --no-extras This will command will attempt to create a k3s master node on the machine you pointed to (via the --ip flag). After that's done, the newly created cluster will be added to your KUBECONFIG , which would could then switch on over to using kubectl config use-context homelab If you just want to get the kubeconfig without creating the cluster again, simply add the --skip-install flag at the end of the command above. Adding nodes to your cluster # Once you've created your master node, it's time to add some workers! Run the following from your local machine !!! warning Not 100% sure whether ssh-key in below command should be the ssh key of the master node or the worker node. k3sup join --ip <worker_ip> --server-ip <master_ip> --user master --ssh-key <master_ssh_key> --k3s-channel latest","title":"Installing k3s"},{"location":"cluster_setup/installing_k3s/#installing-k3s","text":"k3s is a lightweight version of Kubernetes, meant to be used on edge devices, in CI, ARM boards and so on. It's basically a single binary that contains everything to get kubernetes up and running. To help us with installing k3s , we're going to be using a utility package called k3sup","title":"Installing k3s"},{"location":"cluster_setup/installing_k3s/#creating-your-cluster","text":"Getting your cluster up and running is as simple as running this command from your local machine k3sup install --ip <master_ip> --user master --local-path ~/.kube/config --merge --context homelab --ssh-key <ssh_key> --k3s-channel latest --no-extras This will command will attempt to create a k3s master node on the machine you pointed to (via the --ip flag). After that's done, the newly created cluster will be added to your KUBECONFIG , which would could then switch on over to using kubectl config use-context homelab If you just want to get the kubeconfig without creating the cluster again, simply add the --skip-install flag at the end of the command above.","title":"Creating your cluster"},{"location":"cluster_setup/installing_k3s/#adding-nodes-to-your-cluster","text":"Once you've created your master node, it's time to add some workers! Run the following from your local machine !!! warning Not 100% sure whether ssh-key in below command should be the ssh key of the master node or the worker node. k3sup join --ip <worker_ip> --server-ip <master_ip> --user master --ssh-key <master_ssh_key> --k3s-channel latest","title":"Adding nodes to your cluster"},{"location":"cluster_setup/setting_up_flux/","text":"Setting up Flux # Installing Flux # Make a personal token on github with repo privelages Install flux locally ( flux-bin in AUR if using arch) Export GITHUB_TOKEN to shell environment Run the following command flux bootstrap github --owner = ShadyF --repository = homelab --branch = master --path = cluster/base --personal Reconciling using flux # # Reconcile gitcontroller (given that flux-system is the name of the gitcontroller) flux reconcile source git flux-system # Reconcile kustomization (given that apps is the name of the kustomization controller) flux reconcile kustomization apps # Reconcile a helm release flux reconcile helmrelease oauth2-proxy -n networking","title":"Setting up Flux"},{"location":"cluster_setup/setting_up_flux/#setting-up-flux","text":"","title":"Setting up Flux"},{"location":"cluster_setup/setting_up_flux/#installing-flux","text":"Make a personal token on github with repo privelages Install flux locally ( flux-bin in AUR if using arch) Export GITHUB_TOKEN to shell environment Run the following command flux bootstrap github --owner = ShadyF --repository = homelab --branch = master --path = cluster/base --personal","title":"Installing Flux"},{"location":"cluster_setup/setting_up_flux/#reconciling-using-flux","text":"# Reconcile gitcontroller (given that flux-system is the name of the gitcontroller) flux reconcile source git flux-system # Reconcile kustomization (given that apps is the name of the kustomization controller) flux reconcile kustomization apps # Reconcile a helm release flux reconcile helmrelease oauth2-proxy -n networking","title":"Reconciling using flux"},{"location":"cluster_setup/setting_up_raspberry_pi/","text":"Setting up Raspberry Pi for k3s # Info The following guide was heavily inspired / has snippets from this medium tutorial Info This guide assumes that you have already installed Ubuntu Server 21.04 on your Raspberry Pi Logging into Raspberry Pi via SSH # First things first, we need to login to our Raspberry Pi before doing anything. If this is your first time connecting to it, you'll need to connect your Raspberry Pi to your router via ethernet cable. We'll enable Wi-Fi later on in this section. From your router's dashboard, you'll need to figure out which IP was assigned to the Raspberry Pi. The rest of this guide will assume the Raspberry Pi has an internal IP of 192.168.1.100 assigned to it via the router's DHCP. Once you have your IP, time to SSH into this bad boy. ssh ubuntu@192.168.1.100 Note The default username and password for a fresh Ubuntu Server 21.04 install should be ubuntu / ubuntu . Don't worry, you'll be prompted to change this once you login for the first time. Creating a new user # Next up, let's create a new user that represents what this node will be doing. Assuming this Raspberry Pi will be our master node, we're going to create a new user called master sudo adduser master Let's now take all the groups that belonged to the ubuntu and add them to our newly created master user # Running the following command while logged in as ubuntu # should give you a list of all the groups the ubuntu user belongs to groups # Assign the same groups to master sudo usermod -a -G adm,dialout,cdrom,floppy,sudo,audio,dip,video,plugdev,netdev,lxd master Before deleting the ubuntu user, let's first make sure we can login with master ssh master@192.168.1.100 If all goes well, we should can now safely remove the default user sudo deluser --remove-home ubuntu Change default hostname # Let's change the hostname from the default to something more meaningful. Since this node will be our master node, we're going to change it to k8-m1 sudo hostnamectl set-hostname k8-m1 Also, since Ubuntu Server 21.04 uses cloud-init , we're going to have the following line in /etc/cloud/cloud.cfg sudo nano /etc/cloud/cloud.cfg # Change preserve_hostname to true preserve_hostname : true Securing SSH access # Note This section assumes that you're familiar with Key-Based authentication and that you already have a public / private key pair. If not, you can generate one using the following instructions found in this link Currently, anyone can ssh into our Raspberry Pi if they have our username and password. We're going to change this from password-based authentication to key-based authentication, for added security. From your local machine, Let's copy our key to the master node # This copies the public key (at ~/.ssh/id_k8-m1) to the master node ssh-copy-id -i ~/.ssh/id_k8-m1 master@192.168.1.100 If successful, we should check if we can ssh into the master node with our key, without entering a password ssh -i ~/.ssh/id_k8-m1 master@192.168.1.100 Next up, let's tighten up our ssh config so that we disable password login, enable key-based authentications and disable the ability to login as root sudo nano /etc/ssh/sshd_config Change the following lines From: #PermitRootLogin prohibit-password #PasswordAuthentication yes #PubkeyAuthentication yes To: PermitRootLogin no PasswordAuthentication no PubkeyAuthentication yes Finally, restart the sshd daemon so that the changes take effect sudo systemctl restart sshd.service Setup Linux Control Groups # We need to setup Linux Control Groups that are used for resource monitoring and isolation that are needed by Kubernetes. sudo nano /boot/firmware/cmdline.txt Add the following at the end of the line cgroup_enable=cpuset cgroup_memory=1 cgroup_enable=memory Adding password-less sudo to our user # Note We need our user to have password-less sudo so that k3sup would work correctly in the next step # Run the following from your shell sudo visudo # Add the following at the end of the file master ALL=(ALL) NOPASSWD:ALL (Optional) Enable Wi-Fi on your Raspberry Pi # Warning It's recommended to connect the your cluster nodes via a wired connection for a general stability, and an overall better experience This section will be about how to connect your Raspberry Pi to your network via WiFi 1 First off, edit the following file sudo nano /etc/netplan/50-cloud-init.yaml Paste in the following under networks (don't forget to replace the SSID_name and WiFi_password placeholders) wifis : wlan0 : dhcp4 : true optional : true access-points : \"SSID_name\" : password : \"WiFi_password\" Finally, apply the new netplan for it to take effect sudo netplan apply (Optional) Using a SSD with your RPI # If you're planning on using a SSD with your RPI, it might be useful to follow the instructions found in this article since there's some quirks regarding which USB adapters work properly and some fixes that can be applied. You might also want to look at enabling TRIM . This is OS dependent so I'll leave it up to you to find the appropriate guide. https://itsfoss.com/connect-wifi-terminal-ubuntu/ \u21a9","title":"Setting up Raspberry Pi for k3s"},{"location":"cluster_setup/setting_up_raspberry_pi/#setting-up-raspberry-pi-for-k3s","text":"Info The following guide was heavily inspired / has snippets from this medium tutorial Info This guide assumes that you have already installed Ubuntu Server 21.04 on your Raspberry Pi","title":"Setting up Raspberry Pi for k3s"},{"location":"cluster_setup/setting_up_raspberry_pi/#logging-into-raspberry-pi-via-ssh","text":"First things first, we need to login to our Raspberry Pi before doing anything. If this is your first time connecting to it, you'll need to connect your Raspberry Pi to your router via ethernet cable. We'll enable Wi-Fi later on in this section. From your router's dashboard, you'll need to figure out which IP was assigned to the Raspberry Pi. The rest of this guide will assume the Raspberry Pi has an internal IP of 192.168.1.100 assigned to it via the router's DHCP. Once you have your IP, time to SSH into this bad boy. ssh ubuntu@192.168.1.100 Note The default username and password for a fresh Ubuntu Server 21.04 install should be ubuntu / ubuntu . Don't worry, you'll be prompted to change this once you login for the first time.","title":"Logging into Raspberry Pi via SSH"},{"location":"cluster_setup/setting_up_raspberry_pi/#creating-a-new-user","text":"Next up, let's create a new user that represents what this node will be doing. Assuming this Raspberry Pi will be our master node, we're going to create a new user called master sudo adduser master Let's now take all the groups that belonged to the ubuntu and add them to our newly created master user # Running the following command while logged in as ubuntu # should give you a list of all the groups the ubuntu user belongs to groups # Assign the same groups to master sudo usermod -a -G adm,dialout,cdrom,floppy,sudo,audio,dip,video,plugdev,netdev,lxd master Before deleting the ubuntu user, let's first make sure we can login with master ssh master@192.168.1.100 If all goes well, we should can now safely remove the default user sudo deluser --remove-home ubuntu","title":"Creating a new user"},{"location":"cluster_setup/setting_up_raspberry_pi/#change-default-hostname","text":"Let's change the hostname from the default to something more meaningful. Since this node will be our master node, we're going to change it to k8-m1 sudo hostnamectl set-hostname k8-m1 Also, since Ubuntu Server 21.04 uses cloud-init , we're going to have the following line in /etc/cloud/cloud.cfg sudo nano /etc/cloud/cloud.cfg # Change preserve_hostname to true preserve_hostname : true","title":"Change default hostname"},{"location":"cluster_setup/setting_up_raspberry_pi/#securing-ssh-access","text":"Note This section assumes that you're familiar with Key-Based authentication and that you already have a public / private key pair. If not, you can generate one using the following instructions found in this link Currently, anyone can ssh into our Raspberry Pi if they have our username and password. We're going to change this from password-based authentication to key-based authentication, for added security. From your local machine, Let's copy our key to the master node # This copies the public key (at ~/.ssh/id_k8-m1) to the master node ssh-copy-id -i ~/.ssh/id_k8-m1 master@192.168.1.100 If successful, we should check if we can ssh into the master node with our key, without entering a password ssh -i ~/.ssh/id_k8-m1 master@192.168.1.100 Next up, let's tighten up our ssh config so that we disable password login, enable key-based authentications and disable the ability to login as root sudo nano /etc/ssh/sshd_config Change the following lines From: #PermitRootLogin prohibit-password #PasswordAuthentication yes #PubkeyAuthentication yes To: PermitRootLogin no PasswordAuthentication no PubkeyAuthentication yes Finally, restart the sshd daemon so that the changes take effect sudo systemctl restart sshd.service","title":"Securing SSH access"},{"location":"cluster_setup/setting_up_raspberry_pi/#setup-linux-control-groups","text":"We need to setup Linux Control Groups that are used for resource monitoring and isolation that are needed by Kubernetes. sudo nano /boot/firmware/cmdline.txt Add the following at the end of the line cgroup_enable=cpuset cgroup_memory=1 cgroup_enable=memory","title":"Setup Linux Control Groups"},{"location":"cluster_setup/setting_up_raspberry_pi/#adding-password-less-sudo-to-our-user","text":"Note We need our user to have password-less sudo so that k3sup would work correctly in the next step # Run the following from your shell sudo visudo # Add the following at the end of the file master ALL=(ALL) NOPASSWD:ALL","title":"Adding password-less sudo to our user"},{"location":"cluster_setup/setting_up_raspberry_pi/#optional-enable-wi-fi-on-your-raspberry-pi","text":"Warning It's recommended to connect the your cluster nodes via a wired connection for a general stability, and an overall better experience This section will be about how to connect your Raspberry Pi to your network via WiFi 1 First off, edit the following file sudo nano /etc/netplan/50-cloud-init.yaml Paste in the following under networks (don't forget to replace the SSID_name and WiFi_password placeholders) wifis : wlan0 : dhcp4 : true optional : true access-points : \"SSID_name\" : password : \"WiFi_password\" Finally, apply the new netplan for it to take effect sudo netplan apply","title":"(Optional) Enable Wi-Fi on your Raspberry Pi"},{"location":"cluster_setup/setting_up_raspberry_pi/#optional-using-a-ssd-with-your-rpi","text":"If you're planning on using a SSD with your RPI, it might be useful to follow the instructions found in this article since there's some quirks regarding which USB adapters work properly and some fixes that can be applied. You might also want to look at enabling TRIM . This is OS dependent so I'll leave it up to you to find the appropriate guide. https://itsfoss.com/connect-wifi-terminal-ubuntu/ \u21a9","title":"(Optional) Using a SSD with your RPI"},{"location":"miscellaneous/cloudflare_ddns_not_working_with_openwrt/","text":"Cloudflare DDNS not working with OpenWRT based routers # Solution to the problem can be found in this forum post TLDR - Should be ip@domain.com rather than ip.domain.com proxied parameter not working when using Gargoyle # Using Gargoyle v1.12.0, you'll encounter another issue, the DDNS record won't be proxied. This is because the cloudflare-dns script doesn't send the proxied parameter which defaults to false To fix this, we're going to have to edit the Cloudflare DDNS script # ssh into gargoyle router ssh root@192.168.1.1 -i gargoyle # edit cloudflare ddns script with vim vim /plugin_root/usr/lib/ddns-gargoyle/cloudflare-ddns-helper.sh # Go down to the end of the file and you should find this line { \"id\" : \" $ZONEID \" , \"type\" : \"A\" , \"name\" : \" $HOST \" , \"content\" : \" $LOCAL_IP \" } # Add to it the proxied parameter so that it would be like this { \"id\" : \" $ZONEID \" , \"type\" : \"A\" , \"name\" : \" $HOST \" , \"content\" : \" $LOCAL_IP \" , \"proxied\" :true }","title":"Cloudflare DDNS not working with OpenWRT based routers"},{"location":"miscellaneous/cloudflare_ddns_not_working_with_openwrt/#cloudflare-ddns-not-working-with-openwrt-based-routers","text":"Solution to the problem can be found in this forum post TLDR - Should be ip@domain.com rather than ip.domain.com","title":"Cloudflare DDNS not working with OpenWRT based routers"},{"location":"miscellaneous/cloudflare_ddns_not_working_with_openwrt/#proxied-parameter-not-working-when-using-gargoyle","text":"Using Gargoyle v1.12.0, you'll encounter another issue, the DDNS record won't be proxied. This is because the cloudflare-dns script doesn't send the proxied parameter which defaults to false To fix this, we're going to have to edit the Cloudflare DDNS script # ssh into gargoyle router ssh root@192.168.1.1 -i gargoyle # edit cloudflare ddns script with vim vim /plugin_root/usr/lib/ddns-gargoyle/cloudflare-ddns-helper.sh # Go down to the end of the file and you should find this line { \"id\" : \" $ZONEID \" , \"type\" : \"A\" , \"name\" : \" $HOST \" , \"content\" : \" $LOCAL_IP \" } # Add to it the proxied parameter so that it would be like this { \"id\" : \" $ZONEID \" , \"type\" : \"A\" , \"name\" : \" $HOST \" , \"content\" : \" $LOCAL_IP \" , \"proxied\" :true }","title":"proxied parameter not working when using Gargoyle"},{"location":"miscellaneous/cloudflare_dns_challenge/","text":"Using cloudflare DNS challenge instead of basic acme challenge # First things first, you'll need to change your domain's DNS to cloudflare. Use cloudflare nameservers instead of namecheap https://www.namecheap.com/support/knowledgebase/article.aspx/9607/2210/how-to-set-up-dns-records-for-your-domain-in-cloudflare-account/ See https://cert-manager.io/docs/configuration/acme/dns01/cloudflare/ Generating cloudflare API token # https://github.com/k8s-at-home/template-cluster-k3s#cloud-cloudflare-api-token See https://www.reddit.com/r/selfhosted/comments/ga02px/you_should_probably_know_about_letsencrypt_dns/","title":"Using cloudflare DNS challenge instead of basic acme challenge"},{"location":"miscellaneous/cloudflare_dns_challenge/#using-cloudflare-dns-challenge-instead-of-basic-acme-challenge","text":"First things first, you'll need to change your domain's DNS to cloudflare. Use cloudflare nameservers instead of namecheap https://www.namecheap.com/support/knowledgebase/article.aspx/9607/2210/how-to-set-up-dns-records-for-your-domain-in-cloudflare-account/ See https://cert-manager.io/docs/configuration/acme/dns01/cloudflare/","title":"Using cloudflare DNS challenge instead of basic acme challenge"},{"location":"miscellaneous/cloudflare_dns_challenge/#generating-cloudflare-api-token","text":"https://github.com/k8s-at-home/template-cluster-k3s#cloud-cloudflare-api-token See https://www.reddit.com/r/selfhosted/comments/ga02px/you_should_probably_know_about_letsencrypt_dns/","title":"Generating cloudflare API token"},{"location":"miscellaneous/cloudflare_port_forwarding_openwrt/","text":"Restrict Port Forwarding to only allow Cloudflare IPs using OpenWRT # Default firewall rules only allow for one source IP to be defined when created a rule. Hence, there's two options when you want to create a rule that uses multiple Source IPs: Repeat the firewall multiple times Use ipset (See here ) We're going with the second option as it's much easier. In /etc/config/firewall add the following config ipset option name 'cloudflareips' option match 'src_net' option storage 'hash' option enabled '1' list entry '103.21.244.0/22' list entry '103.22.200.0/22' list entry '103.31.4.0/22' list entry '104.16.0.0/13' list entry '104.24.0.0/14' list entry '108.162.192.0/18' list entry '131.0.72.0/22' list entry '141.101.64.0/18' list entry '162.158.0.0/15' list entry '172.64.0.0/13' list entry '173.245.48.0/20' list entry '188.114.96.0/20' list entry '190.93.240.0/20' list entry '197.234.240.0/22' list entry '198.41.128.0/17' Now edit your port forwardings (called redirect in /etc/config/firewall ) to utilize the newly created ipset Again, in /etc/config/firewall config redirect option target 'DNAT' option name 'KubeHTTP' option src 'wan' option ipset 'cloudflareips' # <- This like here option src_dport '80' option dest 'lan' option dest_ip '<internal_ip>' option dest_port '80' list proto 'tcp' config redirect option target 'DNAT' option name 'KubeHTTPS' list proto 'tcp' option src 'wan' option ipset 'cloudflareips' # <- This like here option src_dport '443' option dest 'lan' option dest_ip '<internal_ip>' option dest_port '443' Finally, reload the firewall by running /etc/init.d/firewall reload https://openwrt.org/docs/guide-user/firewall/firewall_configuration \u21a9","title":"Restrict Port Forwarding to only allow Cloudflare IPs using OpenWRT"},{"location":"miscellaneous/cloudflare_port_forwarding_openwrt/#restrict-port-forwarding-to-only-allow-cloudflare-ips-using-openwrt","text":"Default firewall rules only allow for one source IP to be defined when created a rule. Hence, there's two options when you want to create a rule that uses multiple Source IPs: Repeat the firewall multiple times Use ipset (See here ) We're going with the second option as it's much easier. In /etc/config/firewall add the following config ipset option name 'cloudflareips' option match 'src_net' option storage 'hash' option enabled '1' list entry '103.21.244.0/22' list entry '103.22.200.0/22' list entry '103.31.4.0/22' list entry '104.16.0.0/13' list entry '104.24.0.0/14' list entry '108.162.192.0/18' list entry '131.0.72.0/22' list entry '141.101.64.0/18' list entry '162.158.0.0/15' list entry '172.64.0.0/13' list entry '173.245.48.0/20' list entry '188.114.96.0/20' list entry '190.93.240.0/20' list entry '197.234.240.0/22' list entry '198.41.128.0/17' Now edit your port forwardings (called redirect in /etc/config/firewall ) to utilize the newly created ipset Again, in /etc/config/firewall config redirect option target 'DNAT' option name 'KubeHTTP' option src 'wan' option ipset 'cloudflareips' # <- This like here option src_dport '80' option dest 'lan' option dest_ip '<internal_ip>' option dest_port '80' list proto 'tcp' config redirect option target 'DNAT' option name 'KubeHTTPS' list proto 'tcp' option src 'wan' option ipset 'cloudflareips' # <- This like here option src_dport '443' option dest 'lan' option dest_ip '<internal_ip>' option dest_port '443' Finally, reload the firewall by running /etc/init.d/firewall reload https://openwrt.org/docs/guide-user/firewall/firewall_configuration \u21a9","title":"Restrict Port Forwarding to only allow Cloudflare IPs using OpenWRT"},{"location":"miscellaneous/enabling_WakeOnLan_on_NIC/","text":"Enabling WakeOnLan on NIC # Info Adapted from https://www.techrepublic.com/article/how-to-enable-wake-on-lan-in-ubuntu-server-18-04/ To enable WOL on a NIC in ubuntu, we're going to have to create a systemd service. Start by running the following command sudo nano /etc/systemd/system/wol.service In that file, paste the following [Unit] Description=Configure Wake On LAN [Service] Type=oneshot ExecStart=/sbin/ethtool -s INTERFACE wol g [Install] WantedBy=basic.target Afterwards, we need to start the systemd service to take effect immediately and enable it so that it runs on each startup # start the service for the current session sudo systemctl start wol.service # enable the service to run on each startup sudo systemctl enable wol.service","title":"Enabling Wake on Lan on NIC"},{"location":"miscellaneous/enabling_WakeOnLan_on_NIC/#enabling-wakeonlan-on-nic","text":"Info Adapted from https://www.techrepublic.com/article/how-to-enable-wake-on-lan-in-ubuntu-server-18-04/ To enable WOL on a NIC in ubuntu, we're going to have to create a systemd service. Start by running the following command sudo nano /etc/systemd/system/wol.service In that file, paste the following [Unit] Description=Configure Wake On LAN [Service] Type=oneshot ExecStart=/sbin/ethtool -s INTERFACE wol g [Install] WantedBy=basic.target Afterwards, we need to start the systemd service to take effect immediately and enable it so that it runs on each startup # start the service for the current session sudo systemctl start wol.service # enable the service to run on each startup sudo systemctl enable wol.service","title":"Enabling WakeOnLan on NIC"},{"location":"miscellaneous/metallb_not_working_raspberry_wifi/","text":"Getting MetalLB to work on Raspberry Pi 4's Wifi # Problem # MetalLB in ARP mode doesn't work on Raspberry Pi if the Wifi interface is used. The exact details of the issue can be found here Solution # We'll need to change the Wifi adapter to use promiscuous mode. This can be done by running the following command: ip link set wlan0 promisc on However, you'll have to run this command after each reboot. To have this run automatically on startup, we can use crontab . crontab -e # Add the following line to crontab @reboot ip link set wlan0 promisc on","title":"Getting MetalLB to work on Raspberry Pi 4's Wifi"},{"location":"miscellaneous/metallb_not_working_raspberry_wifi/#getting-metallb-to-work-on-raspberry-pi-4s-wifi","text":"","title":"Getting MetalLB to work on Raspberry Pi 4's Wifi"},{"location":"miscellaneous/metallb_not_working_raspberry_wifi/#problem","text":"MetalLB in ARP mode doesn't work on Raspberry Pi if the Wifi interface is used. The exact details of the issue can be found here","title":"Problem"},{"location":"miscellaneous/metallb_not_working_raspberry_wifi/#solution","text":"We'll need to change the Wifi adapter to use promiscuous mode. This can be done by running the following command: ip link set wlan0 promisc on However, you'll have to run this command after each reboot. To have this run automatically on startup, we can use crontab . crontab -e # Add the following line to crontab @reboot ip link set wlan0 promisc on","title":"Solution"},{"location":"miscellaneous/tips_and_tricks/","text":"Here are some tips and tricks that might be of use. Change kubectl context # kubectl config use-context homelab Change default shell # chsh --shell /usr/bin/fish Retrieve Raspberry pi's CPU temp in Ubuntu # cat /sys/class/thermal/thermal_zone0/temp Debug pod stuck in crashloop # Force the pod to run the sleep command rather than what it has as an entrypoint, allowing you to SSH into it and debug what's going on Add the following to your pod's definition command : [ 'sleep' ] args : [ 'infinity' ] Exporting GPG key from one machine to another # Follow the steps provided in this guide Creating a docker registry secret yaml file # kubectl create secret docker-registry regcred --docker-server = \"https://index.docker.io/v1/\" --docker-username = <username> --docker-password = <password> --docker-email = <email> --dry-run = client -oyaml > regcred.yaml Remove useless ubuntu stuff # # Remove snapd, takes up CPU and not needed on a kube node sudo apt autoremove --purge snapd To see the data created in a longhorn volume # use lsblk -f or df -H to find your desired PVC path cd into it Setting up log2ram to reduce SD card strain / SSD writes # https://github.com/azlux/log2ram","title":"Tips and Tricks"},{"location":"miscellaneous/tips_and_tricks/#change-kubectl-context","text":"kubectl config use-context homelab","title":"Change kubectl context"},{"location":"miscellaneous/tips_and_tricks/#change-default-shell","text":"chsh --shell /usr/bin/fish","title":"Change default shell"},{"location":"miscellaneous/tips_and_tricks/#retrieve-raspberry-pis-cpu-temp-in-ubuntu","text":"cat /sys/class/thermal/thermal_zone0/temp","title":"Retrieve Raspberry pi's CPU temp in Ubuntu"},{"location":"miscellaneous/tips_and_tricks/#debug-pod-stuck-in-crashloop","text":"Force the pod to run the sleep command rather than what it has as an entrypoint, allowing you to SSH into it and debug what's going on Add the following to your pod's definition command : [ 'sleep' ] args : [ 'infinity' ]","title":"Debug pod stuck in crashloop"},{"location":"miscellaneous/tips_and_tricks/#exporting-gpg-key-from-one-machine-to-another","text":"Follow the steps provided in this guide","title":"Exporting GPG key from one machine to another"},{"location":"miscellaneous/tips_and_tricks/#creating-a-docker-registry-secret-yaml-file","text":"kubectl create secret docker-registry regcred --docker-server = \"https://index.docker.io/v1/\" --docker-username = <username> --docker-password = <password> --docker-email = <email> --dry-run = client -oyaml > regcred.yaml","title":"Creating a docker registry secret yaml file"},{"location":"miscellaneous/tips_and_tricks/#remove-useless-ubuntu-stuff","text":"# Remove snapd, takes up CPU and not needed on a kube node sudo apt autoremove --purge snapd","title":"Remove useless ubuntu stuff"},{"location":"miscellaneous/tips_and_tricks/#to-see-the-data-created-in-a-longhorn-volume","text":"use lsblk -f or df -H to find your desired PVC path cd into it","title":"To see the data created in a longhorn volume"},{"location":"miscellaneous/tips_and_tricks/#setting-up-log2ram-to-reduce-sd-card-strain-ssd-writes","text":"https://github.com/azlux/log2ram","title":"Setting up log2ram to reduce SD card strain / SSD writes"}]}