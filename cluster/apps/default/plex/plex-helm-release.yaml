---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: plex
  namespace: default
spec:
  interval: 5m
  chart:
    spec:
      # renovate: registryUrl=https://k8s-at-home.com/charts/
      chart: plex
      version: 6.4.3
      sourceRef:
        kind: HelmRepository
        name: k8s-at-home-charts
        namespace: flux-system
      interval: 5m
  dependsOn:
    - name: longhorn
      namespace: longhorn-system
  values:
    image:
      repository: linuxserver/plex
      tag: 1.42.2.10156-f737b826c-ls282
    env:
      TZ: "Africa/Cairo"
      # See https://www.devwithimagination.com/2019/08/21/plex-docker-and-the-problem-of-always-appearing-as-remote/
      ADVERTISE_IP: "https://plex.${SECRET_DOMAIN}:443/,http://192.168.1.245:32400/"
      ALLOWED_NETWORKS: "10.0.0.0/8,192.168.1.0/24"
    envFrom:
      - secretRef:
          # TODO: PLEX_CLAIM doesn't seem to work with linuxserver.io, have to do it manually by opening plex at IP
          name: plex-secrets
    podSecurityContext:
      fsGroup: 1001
      supplementalGroups:
        - 44
        - 109
        - 100
    service:
      main:
        # Not sure why this service is needed. See https://www.debontonline.com/2021/01/part-14-deploy-plexserver-yaml-with.html
        type: LoadBalancer
        # Needed since plex only considers clients as local if they're on the same subnet
        externalTrafficPolicy: Local

        # Needed if sharing UDP and TCP services, not sure if this is actually needed here though
        annotations:
          metallb.universe.tf/allow-shared-ip: plex
          metallb.universe.tf/loadBalancerIPs: 192.168.1.245
    ingress:
      main:
        enabled: true
        ingressClassName: "external"
        annotations:
          external-dns/is-public: "true"
          external-dns.alpha.kubernetes.io/target: "ipv4.${SECRET_DOMAIN}"
        hosts:
          - host: "plex.${SECRET_DOMAIN}"
            paths:
              - path: /
                pathType: Prefix
        tls:
          - hosts:
              - "plex.${SECRET_DOMAIN}"

    persistence:
      # Settings config to an NFS volume will cause issues and hangs. iSCSI volume should fix the issue.
      # See https://www.reddit.com/r/PleX/comments/ezbmy0/running_plex_in_kubernetes_finally_working/
      config:
        enabled: true
        existingClaim: plex-csi-config-pvc
      transcode:
        enabled: true
        type: emptyDir
      nfs-big-media-pvc:
        enabled: true
        existingClaim: nfs-big-media-pvc
        # To be able to delete movies directly from plex
        readOnly: false

    # Disallow running on arm64
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
                - key: kubernetes.io/arch
                  operator: NotIn
                  values:
                    - arm64

    nodeSelector:
      intel.feature.node.kubernetes.io/gpu: "true"

    resources:
      requests:
        gpu.intel.com/i915: "1"
        memory: 983Mi
      limits:
        gpu.intel.com/i915: "1"
        memory: 983Mi
    addons:
      promtail:
        enabled: true
        image:
          repository: grafana/promtail
          tag: 3.5.6
        loki: http://loki.monitoring.svc.cluster.local:3100/loki/api/v1/push
        logs:
          - name: promtail/plex
            path: "/config/Library/Application Support/Plex Media Server/Logs/*.log"
          - name: promtail/plex/plugins
            path: "/config/Library/Application Support/Plex Media Server/Logs/PMS Plugin Logs/*.log"
        volumeMounts:
          - name: config
            mountPath: /config
            readOnly: true
        securityContext:
          runAsUser: 0